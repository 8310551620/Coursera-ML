
\documentclass[11pt]{article} % use larger type; default would be 10pt
\usepackage{framed}
\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...
\usepackage{framed}

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
\begin{document}

%=================================================================%

\section{ML Week 5}
\subsection*{Overfitting and Regularization}

\begin{itemize}
\item If one neural network overfits the training set, one reasonable step is to
increase the regularization parameter $\lambda$.
\item For computational efficiency, after we performed gradient checking to verify that our back-propagation 
code is correct, we usually disable gradient checkking before using back-propagation to train
the network
\end{itemize}
%--------------------------%

\subsection*{Exercise}
Let $ J(\theta) = 3\theta^2 + 2$

Let $\theta = 1$ and $\epsilon = 0.01$

Use the formula to numerically compute an approximation to the derivative of $\theta$
at $theta = 1$

\[
\frac{J(\theta + \epsilon) - J(\theta + \epsilon)}{2\epsilon} 
= \frac{(3(1.01)^2 + 2$)-(3(0.99)^2 + 2$)}{0.002} 
= 9.003

\]
%=================================================================%

\section{Week 6 Advice for Applying Machine Learning}

\subsection*{Question 1. }
You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?



Neither

High variance

High bias
%-----------------------------------------------------------%
\subsection*{Question 2. }
Suppose you have implemented regularized logistic regression  to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large 
errors with its predictions on the new images. However, your

hypothesis performs well (has low error) on the

training set. Which of the following are promising steps to

take? Check all that apply.

\begin{itemize}
\item 
Try increasing the regularization parameter $\lambda$.
\item 
Try evaluating the hypothesis on a cross validation set rather than the test set.
\item 
Try using a smaller set of features.
\item 
Try decreasing the regularization parameter $\lambda$.
\end{itemize}
%-----------------------------------------------------------%
\subsection*{Question 3. }
Suppose you have implemented regularized logistic regression

to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new

set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis

performs poorly on the training set. Which of the following might be promising steps to take? Check all that

apply.

\begin{itemize}
\item Try decreasing the regularization parameter $\lambda$.

\item Use fewer training examples.

\item Try evaluating the hypothesis on a cross validation set rather than the test set.

\item Try adding polynomial features.
\end{itemize}
%-----------------------------------------------------------%
\subsection*{Question 4. }
Which of the following statements are true? Check all that apply.

Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest test set error.

Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest cross validation error.

The performance of a learning algorithm on the training set will typically be better than its performance on the test set.

Suppose you are training a regularized linear regression model.The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest training set error.

%-----------------------------------------------------------%
\subsection*{Question 5. }
Which of the following statements are true? Check all that apply.

A model with more parameters is more prone to overfitting and typically has higher variance. SELECTED

If the training and test errors are about the same, adding more features will not help improve the results. SELECTED

If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.

If a learning algorithm is suffering from high bias, only adding more training examples may not improve the test error significantly.

\end{document}
